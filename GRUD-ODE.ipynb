{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GRUD-ODE.ipynb","provenance":[],"authorship_tag":"ABX9TyOndb4c8mJyw0G/CFfZtzsA"},"kernelspec":{"name":"python3610jvsc74a57bd004273c182938acab5b8103d4fa5a036ac15426ac6c2e8bb7ba536b8571454538","display_name":"Python 3.6.10 64-bit ('tf': conda)"},"metadata":{"interpreter":{"hash":"7daa67501fb74f31bc6bea614c176a1d9f31c27b15c979db2893dec52b20fdf8"}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xnUdaf15ZWvK","executionInfo":{"status":"ok","timestamp":1617347123857,"user_tz":-60,"elapsed":29387,"user":{"displayName":"高若曦","photoUrl":"","userId":"07578031693675811828"}},"outputId":"9fe90af6-e558-4112-98da-899359360901"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":7,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m<ipython-input-7-01791cb58784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYpvyUHqZmh0","executionInfo":{"status":"ok","timestamp":1617347129243,"user_tz":-60,"elapsed":1001,"user":{"displayName":"高若曦","photoUrl":"","userId":"07578031693675811828"}},"outputId":"ef8da54a-8b54-4b72-f216-bde21b70b8a6"},"source":["!ls \"/content/drive/My Drive\""],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["'ls' is not recognized as an internal or external command,\noperable program or batch file.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hths4suqZohA","outputId":"f0d17db7-c924-4ae2-aa7f-674d797af85b","tags":["outputPrepend"]},"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","import torch\n","import numpy as np\n","import math\n","import torch.utils.data as utils\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score\n","from keras.utils import to_categorical\n","from scipy.integrate import odeint\n","import matplotlib.pyplot as plt\n","\n","rootpath = '/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/2019/lnt/data/Physionet2012/'\n","#all_x_add = np.load(rootpath + 'input/all_x_add.npy', allow_pickle=True)\n","#dataset = np.load(rootpath + 'input/dataset.npy', allow_pickle=True)\n","dataset = np.load(rootpath + 'X.npy', allow_pickle=True)\n","dt = np.load(rootpath + 'dt.npy', allow_pickle=True)\n","# 0:death 1:length of stay(<3) 2:Cardical 3:Surgery\n","y = np.load(rootpath + 'y.npy', allow_pickle=True)\n","y1 = y[:,0:1] \n","\n","class GRUD_ODECell(torch.nn.Module):\n","  def __init__(self, input_size, hidden_size):\n","    super().__init__()\n","    \n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","    \n","    self.inputzeros = torch.autograd.Variable(torch.zeros(input_size))\n","    self.hiddenzeros = torch.autograd.Variable(torch.zeros(hidden_size))\n","    \n","    self.w_dg_x = torch.nn.Parameter(torch.Tensor(input_size))\n","    self.w_dg_h = torch.nn.Parameter(torch.Tensor(hidden_size,input_size))\n","    self.b_dg_x = torch.nn.Parameter(torch.Tensor(input_size))\n","    self.b_dg_h = torch.nn.Parameter(torch.Tensor(hidden_size))\n","\n","    self.lin_xh = torch.nn.Linear(input_size, hidden_size, bias=True)\n","    self.lin_xz = torch.nn.Linear(input_size, hidden_size, bias=True)\n","    self.lin_xr = torch.nn.Linear(input_size, hidden_size, bias=True)\n","    self.lin_hu = torch.nn.Linear(hidden_size, hidden_size, bias=False)\n","    self.lin_hz = torch.nn.Linear(hidden_size, hidden_size, bias=False)\n","    self.lin_hr = torch.nn.Linear(hidden_size, hidden_size, bias=False)\n","    self.lin_mu = torch.nn.Linear(input_size, hidden_size, bias=False)\n","    self.lin_mz = torch.nn.Linear(input_size, hidden_size, bias=False)\n","    self.lin_mr = torch.nn.Linear(input_size, hidden_size, bias=False)\n","\n","    # self.w_dg_h = torch.nn.Parameter(torch.Tensor(hidden_size))\n","    # # z\n","    # self.w_xz = torch.nn.Parameter(torch.Tensor(input_size))\n","    # self.w_hz = torch.nn.Parameter(torch.Tensor(hidden_size))\n","    # self.w_mz = torch.nn.Parameter(torch.Tensor(input_size))\n","\n","    # # r\n","    # self.w_xr = torch.nn.Parameter(torch.Tensor(input_size))\n","    # self.w_hr = torch.nn.Parameter(torch.Tensor(hidden_size))\n","    # self.w_mr = torch.nn.Parameter(torch.Tensor(input_size))\n","\n","    # # h_tilde\n","    # self.w_xh = torch.nn.Parameter(torch.Tensor(input_size))\n","    # self.w_hh = torch.nn.Parameter(torch.Tensor(hidden_size))\n","    # self.w_mh = torch.nn.Parameter(torch.Tensor(input_size))\n","\n","    # # bias\n","    # self.b_z = torch.nn.Parameter(torch.Tensor(hidden_size))\n","    # self.b_r = torch.nn.Parameter(torch.Tensor(hidden_size))\n","    # self.b_h = torch.nn.Parameter(torch.Tensor(hidden_size))\n","\n","  def forward(self, h, x, m, d, prex, mean):\n","    gamma_x = torch.exp(-torch.max(self.inputzeros, (self.w_dg_x*d + self.b_dg_x)))\n","    gamma_h = torch.exp(-torch.max(self.hiddenzeros, (torch.matmul(self.w_dg_h, d) + self.b_dg_h)))\n","    # gamma_h = torch.exp(-torch.max(self.hiddenzeros, (self.w_dg_h*d + self.b_dg_h)))\n","\n","    x = m * x + (1 - m) * (gamma_x * prex + (1 - gamma_x) * mean)\n","    h = gamma_h * h\n","    \n","    r = torch.sigmoid(self.lin_xr(x) + self.lin_hr(h) + self.lin_mr(m))\n","    z = torch.sigmoid(self.lin_xz(x) + self.lin_hz(h) + self.lin_mz(m))\n","    u = torch.tanh(self.lin_xh(x) + self.lin_hu(r * h) + self.lin_mu(m))\n","    # z = torch.sigmoid((self.w_xz*x + self.w_hz*h + self.w_mz*m + self.b_z))\n","    # r = torch.sigmoid((self.w_xr*x + self.w_hr*h + self.w_mr*m + self.b_r))\n","    # u = torch.tanh((self.w_xh*x + self.w_hh*(r * h) + self.w_mh*m + self.b_h))\n","\n","    dh = z * (u - h)\n","    return dh, x\n","\n","class GRUD_ODE(torch.nn.Module):  \n","  def __init__(self, input_size, hidden_size, output_size, num_layers, dropout_type, dropout):\n","    super().__init__()\n","\n","    self.dropout_type = dropout_type\n","    self.dropout = dropout\n","    self.num_layers = num_layers\n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","    self.output_size = output_size\n","    self.cell = GRUD_ODECell(input_size, hidden_size)\n","    # self.lin_1 = torch.nn.Linear(hidden_size[0], hidden_size[1], bias=True)\n","    # self.lin_2 = torch.nn.Linear(hidden_size[1], output_size, bias=True)\n","    # self.lin = torch.nn.Sequential(\n","    #             self.lin_1,\n","    #             torch.nn.ReLU(),\n","    #             self.lin_2\n","    #             )\n","    self.lin = torch.nn.Linear(hidden_size, output_size, bias=True)\n","    self.reset_parameters()\n","  \n","  def reset_parameters(self):\n","    #stdv = 1.0 / math.sqrt(self.hidden_size)\n","    #for weight in self.parameters():\n","    #  torch.nn.init.uniform_(weight, -stdv, stdv)\n","    for params in self.parameters():\n","      torch.nn.init.normal_(params, mean=0, std=0.1)\n","\n","  def forward(self, input, dt):\n","    X = torch.squeeze(input[0]) \n","    Mask = torch.squeeze(input[1]) \n","    Delta = torch.squeeze(input[2]) \n","    #dt = torch.squeeze(dt) \n","    h = torch.autograd.Variable(torch.zeros(self.hidden_size))\n","    prex = torch.autograd.Variable(torch.zeros(self.input_size))\n","    mean = torch.squeeze(torch.sum(X,1))/(1e-6+torch.squeeze(torch.sum((Mask!=0),1)))\n","    for layer in range(self.num_layers):\n","      if dt[layer]==0:\n","        break\n","\n","      x = torch.squeeze(X[:,layer])\n","      m = torch.squeeze(Mask[:,layer])\n","      d = torch.squeeze(Delta[:,layer])\n","      if self.dropout == 0:\n","        dh, prex = self.cell(h, x, m, d, prex, mean)\n","        h = h + dt[layer]*dh\n","        #h = h + dh\n","      elif self.dropout_type == 'Moon':\n","        dh, prex = self.cell(h, x, m, d, prex, mean)\n","        h = h + dt[layer]*dh\n","        #h = h + dh\n","        dropout = torch.nn.Dropout(p=self.dropout)\n","        h = dropout(h)\n","      elif self.dropout_type == 'Gal':\n","        dropout = torch.nn.Dropout(p=self.dropout)\n","        h = dropout(h)\n","        dh, prex = self.cell(h, x, m, d, prex, mean)\n","        h = h + dt[layer]*dh\n","        #h = h + dh\n","      elif self.dropout_type == 'mloss':\n","        dropout = torch.nn.Dropout(p=self.dropout)\n","        dh, prex = self.cell(h, x, m, d, prex, mean)\n","        dh = dropout(dh)\n","        h = h + dt[layer]*dh\n","        #h = h + dh    \n","    output = self.lin(h)      \n","    output = torch.sigmoid(output)\n","    return output\n","\n","\n","def fit(model, criterion, learning_rate,\\\n","        train_dataloader, dev_dataloader,\\\n","        learning_rate_decay, n_epochs):\n","  epoch_losses = []\n","  best_per = -1\n","  for epoch in range(n_epochs):   \n","    if learning_rate_decay != 0:\n","      if  epoch % learning_rate_decay == 0:\n","        learning_rate = learning_rate/2\n","        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","    elif learning_rate_decay == 0:\n","      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n","      \n","    # train the model\n","    losses = []\n","    model.train()\n","\n","\n","    for train_data, train_label, dt in train_dataloader:\n","      optimizer.zero_grad() \n","      train_data = torch.squeeze(train_data)\n","      train_label = torch.squeeze(train_label)\n","      dt = torch.squeeze(dt) \n","      y_pred = model(train_data, dt)\n","\n","      #pred.append(torch.argmax(y_pred,dim=0).item())\n","      # pred.append(y_pred.item())\n","      # label.append(train_label.item())\n","      #loss = criterion(y_pred.view(1,-1), train_label.long())\n","      loss = criterion(y_pred, train_label)\n","      # acc.append(\n","      #     accuracy_score([train_label.item()], [(y_pred.item()>0.5)+0])\n","      # )\n","      losses.append(loss.item())\n","\n","      loss.backward()\n","      optimizer.step()\n","\n","    # train_acc = np.mean(acc)\n","    train_loss = np.mean(losses)\n","      \n","    # dev loss\n","    losses = []\n","    pred, label = list(), list()\n","    model.eval()\n","    for dev_data, dev_label, dt in dev_dataloader:\n","      dev_data = torch.squeeze(dev_data)\n","      dev_label = torch.squeeze(dev_label)\n","      dt = torch.squeeze(dt)\n","\n","      y_pred = model(dev_data, dt)\n","      \n","      #pred.append(torch.argmax(y_pred,dim=0).item())\n","      pred.append(y_pred.detach().numpy().tolist())\n","      label.append(dev_label.detach().numpy().tolist())\n","      #loss = criterion(y_pred.view(1,-1), train_label.long())\n","      loss = criterion(y_pred, dev_label)\n","      # acc.append(\n","      #     accuracy_score([dev_label.item()], [(y_pred.item()>0.5)+0])\n","      # )\n","      losses.append(loss.item())\n","          \n","    # dev_acc = np.mean(acc)\n","    dev_loss = np.mean(losses)\n","    \n","    pred = np.asarray(pred)\n","    label = np.asarray(label)\n","\n","    # auc_mean, roc_auc = get_performance(predicts=pred, labels=label, best_per=best_per, save_path='./result')\n","    auc_score = roc_auc_score(label, pred)\n","    if auc_score > best_per:\n","      best_per = auc_score\n","      np.save('./result/best_pred_mon.npy', pred)\n","      np.save('./result/best_label_mon.npy', label)\n","    # auc_score_1 = roc_auc_score(label[:,0], pred[:,0])\n","    # auc_score_2 = roc_auc_score(label[:,1], pred[:,1])\n","    # auc_score_3 = roc_auc_score(label[:,2], pred[:,2])\n","    # auc_score_4 = roc_auc_score(label[:,3], pred[:,3])\n","    \n","    print(\"Epoch {}:\\n Train loss: {:.4f}, Dev loss: {:.4f}\\n AUC score: {:.4f}\".format(\n","        epoch+1, train_loss, dev_loss, auc_score))\n","    # print(\"Mortality: {:.4f}, Length of Stay: {:.4f}, Cardiac: {:.4f}, Surgery: {:.4f}\".format(\n","    #     auc_score_1, auc_score_2, auc_score_3, auc_score_4))\n","    # print(\"Mean: {:.4f}, Mortality: {:.4f}, Length of Stay: {:.4f}, Cardiac: {:.4f}, Surgery: {:.4f}\".format(\n","    #     auc_mean, roc_auc['class_0'], roc_auc['class_1'], roc_auc['class_2'], roc_auc['class_3']))\n","  return epoch_losses     \n","\n","\n","def get_performance(predicts, labels, best_per, save_path, task):\n","    num_class = 4\n","    if not isinstance(predicts, np.ndarray):\n","        predicts = np.array(predicts)\n","    if not isinstance(labels, np.ndarray):\n","        labels = np.array(labels)\n","    fpr = dict()\n","    tpr = dict()\n","    roc_auc = dict()\n","    auc_total = 0\n","    # predicts_result = np.zeros(predicts.shape)\n","    # predicts_result[predicts>=0.5]=1\n","    labels[labels<0.5]=0\n","    labels[labels!=0]=1\n","    for i in range(num_class):\n","        class_name = 'class_{}'.format(str(i))\n","        fpr[class_name], tpr[class_name], _ = roc_curve(labels[:, i], predicts[:, i])\n","        roc_auc[class_name] = auc(fpr[class_name], tpr[class_name])\n","        auc_total += roc_auc[class_name]\n","    \n","    auc_mean = auc_total / num_class\n","    roc_auc['macro']= roc_auc_score(labels, predicts, average='macro')\n","    roc_auc['micro'] = roc_auc_score(labels, predicts, average='micro')\n","\n","    colors = cycle(['blue', 'red', 'green', 'black'])\n","\n","    plt.figure(figsize=(40, 25))\n","    for i, color in zip(fpr.keys(), colors):\n","        plt.plot(fpr[i], tpr[i], color=color, lw=1.5,\n","                label='class {0} ({1:0.2f})'\n","                ''.format(i, roc_auc[i]))\n","    plt.plot([0, 1], [0, 1], 'k--', lw=1.5)\n","    plt.xlim([-0.05, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('ROC-AUC')\n","    plt.legend(loc=\"lower right\")\n","    if auc_mean > best_per:\n","        plt.savefig(os.path.join(save_path, '{}_best.png'.format(task)))\n","    print('*'*40+task+'*'*40)\n","    # print('FPR:{}'.format('  '.join([str(round(fpr[x], 2)) for x in fpr.keys()])))\n","    # print('TPR:{}'.format('  '.join([str(round(tpr[x], 2)) for x in tpr.keys()])))\n","    print('AUC:{}'.format('  '.join([str(round(roc_auc[x], 2)) for x in roc_auc.keys()])))\n","    print('AUC_MEAN:{}'.format(auc_mean))\n","    plt.close()\n","    return auc_mean, roc_auc\n","\n","def data_dataloader(dataset, outcomes, dt, \\\n","                    train_proportion = 0.8, dev_proportion = 0.2):\n","    \n","  train_index = int(np.floor(dataset.shape[0] * train_proportion))\n","  \n","  # split dataset to tarin/dev/test set\n","  # only Mortality\n","  train_data, train_label = dataset[:train_index,:,:,:], outcomes[:train_index, 0]\n","  dev_data, dev_label = dataset[train_index:,:,:,:], outcomes[train_index:,0]  \n","  train_dt, dev_dt = dt[:train_index,:], dt[train_index:,:]\n","    \n","  # ndarray to tensor\n","  train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n","  dev_data, dev_label = torch.Tensor(dev_data), torch.Tensor(dev_label)\n","  train_dt, dev_dt = torch.Tensor(train_dt), torch.Tensor(dev_dt)\n","  \n","  # tensor to dataset\n","  train_dataset = utils.TensorDataset(train_data, train_label, train_dt)\n","  dev_dataset = utils.TensorDataset(dev_data, dev_label, dev_dt)\n","  \n","  # dataset to dataloader \n","  train_dataloader = utils.DataLoader(train_dataset)\n","  dev_dataloader = utils.DataLoader(dev_dataset)\n","  \n","  return train_dataloader, dev_dataloader\n","\n","if __name__ == '__main__':    \n","  input_size = 33 \n","  hidden_size = 10 \n","  output_size = 1\n","  TIME = 203\n","  \n","  #dropout_type : Moon, Gal, mloss\n","  model = GRUD_ODE(input_size=input_size, hidden_size=hidden_size, output_size=output_size, num_layers=TIME, dropout_type='Moon', dropout=0.0)\n","  criterion = torch.nn.BCELoss()\n","  \n","  learning_rate = 0.01\n","  learning_rate_decay = 5\n","  n_epochs = 100\n","  train_dataloader, dev_dataloader = data_dataloader(dataset, y, dt, train_proportion=0.7, dev_proportion=0.3)\n","  epoch_losses = fit(model, criterion, learning_rate,\\\n","                      train_dataloader, dev_dataloader,\\\n","                      learning_rate_decay, n_epochs)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 57:\n"," Train loss: 0.1899, Dev loss: 0.3877\n"," AUC score: 0.8135\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 58:\n"," Train loss: 0.1899, Dev loss: 0.3879\n"," AUC score: 0.8133\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 59:\n"," Train loss: 0.1898, Dev loss: 0.3880\n"," AUC score: 0.8133\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 60:\n"," Train loss: 0.1898, Dev loss: 0.3880\n"," AUC score: 0.8133\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 61:\n"," Train loss: 0.1901, Dev loss: 0.3861\n"," AUC score: 0.8141\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 62:\n"," Train loss: 0.1897, Dev loss: 0.3854\n"," AUC score: 0.8143\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 63:\n"," Train loss: 0.1896, Dev loss: 0.3853\n"," AUC score: 0.8144\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 64:\n"," Train loss: 0.1896, Dev loss: 0.3854\n"," AUC score: 0.8144\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 65:\n"," Train loss: 0.1896, Dev loss: 0.3854\n"," AUC score: 0.8143\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 66:\n"," Train loss: 0.1897, Dev loss: 0.3849\n"," AUC score: 0.8145\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 67:\n"," Train loss: 0.1896, Dev loss: 0.3844\n"," AUC score: 0.8147\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 68:\n"," Train loss: 0.1895, Dev loss: 0.3842\n"," AUC score: 0.8148\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 69:\n"," Train loss: 0.1895, Dev loss: 0.3841\n"," AUC score: 0.8148\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 70:\n"," Train loss: 0.1895, Dev loss: 0.3841\n"," AUC score: 0.8148\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 71:\n"," Train loss: 0.1895, Dev loss: 0.3840\n"," AUC score: 0.8148\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 72:\n"," Train loss: 0.1895, Dev loss: 0.3838\n"," AUC score: 0.8149\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 73:\n"," Train loss: 0.1895, Dev loss: 0.3837\n"," AUC score: 0.8150\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 74:\n"," Train loss: 0.1895, Dev loss: 0.3836\n"," AUC score: 0.8150\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 75:\n"," Train loss: 0.1894, Dev loss: 0.3836\n"," AUC score: 0.8150\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 76:\n"," Train loss: 0.1894, Dev loss: 0.3836\n"," AUC score: 0.8150\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 77:\n"," Train loss: 0.1894, Dev loss: 0.3835\n"," AUC score: 0.8151\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 78:\n"," Train loss: 0.1894, Dev loss: 0.3834\n"," AUC score: 0.8151\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 79:\n"," Train loss: 0.1894, Dev loss: 0.3834\n"," AUC score: 0.8151\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 80:\n"," Train loss: 0.1894, Dev loss: 0.3833\n"," AUC score: 0.8151\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 81:\n"," Train loss: 0.1894, Dev loss: 0.3833\n"," AUC score: 0.8151\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 82:\n"," Train loss: 0.1894, Dev loss: 0.3833\n"," AUC score: 0.8151\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 83:\n"," Train loss: 0.1894, Dev loss: 0.3833\n"," AUC score: 0.8151\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 84:\n"," Train loss: 0.1894, Dev loss: 0.3832\n"," AUC score: 0.8151\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 85:\n"," Train loss: 0.1894, Dev loss: 0.3832\n"," AUC score: 0.8151\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 86:\n"," Train loss: 0.1894, Dev loss: 0.3832\n"," AUC score: 0.8151\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 87:\n"," Train loss: 0.1894, Dev loss: 0.3832\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 88:\n"," Train loss: 0.1894, Dev loss: 0.3832\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 89:\n"," Train loss: 0.1894, Dev loss: 0.3832\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 90:\n"," Train loss: 0.1894, Dev loss: 0.3831\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 91:\n"," Train loss: 0.1894, Dev loss: 0.3832\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 92:\n"," Train loss: 0.1894, Dev loss: 0.3831\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 93:\n"," Train loss: 0.1894, Dev loss: 0.3831\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 94:\n"," Train loss: 0.1894, Dev loss: 0.3831\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 95:\n"," Train loss: 0.1894, Dev loss: 0.3831\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 96:\n"," Train loss: 0.1894, Dev loss: 0.3831\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 97:\n"," Train loss: 0.1894, Dev loss: 0.3831\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 98:\n"," Train loss: 0.1894, Dev loss: 0.3831\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 99:\n"," Train loss: 0.1894, Dev loss: 0.3831\n"," AUC score: 0.8152\n","/media/gsp/48cfceb8-8b77-4141-bba7-da05abd58d95/DevelopEnvironment/Anaconda/envs/tf/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n","  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n","Epoch 100:\n"," Train loss: 0.1894, Dev loss: 0.3831\n"," AUC score: 0.8152\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}